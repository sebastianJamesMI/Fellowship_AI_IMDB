{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_IMDB_BERT_Hub_Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1TctRkJhA_ZxDiBMMDBwDwXBOoZwtmzrv",
      "authorship_tag": "ABX9TyMo63RIWj3sWSzoQvQ/9DxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianJamesMI/Fellowship_AI_IMDB/blob/main/Sentiment_Analysis_IMDB_BERT_Hub_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GarTRYs62E_S"
      },
      "source": [
        "\n",
        "- The objective here is to classify movie reviews as positive or negative. The original reviews were rated on a scale from 1 to 10. For Binary Classification, anything with <= 4 was classfed as negative and anything with >= 7 stars were classified as positive. \n",
        "\n",
        "\n",
        "********************************************************************************\n",
        "\n",
        "I use different strategies to perform this classification task starting with a simple RNN model (LSTM) then using more complex models. \n",
        "\n",
        "******************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This notebook uses fine tuning with BERT. The original source code for this model is available here: \n",
        "\n",
        "https://colab.research.google.com/drive/1934Mm2cwSSfT5bvi78-AExAl-hSfxCbq#scrollTo=hJ0NdZWVdhhG\n",
        "\n",
        "\n",
        "\n",
        "1. Tensorflow NLP tutorials: https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
        "\n",
        "2. Data reading and downloading, Aaron Kub: \n",
        "https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
        "\n",
        "3. Data Reading and Downloading: Georgios Drakos: https://gdcoder.com/sentiment-clas/\n",
        "\n",
        "4. Word Tokenization: Coursera Deep learning NLP courses by Andrew Ng\n",
        "\n",
        "4. An article on Medium by David Mraz: \n",
        "https://medium.com/atheros/text-classification-with-transformers-in-tensorflow-2-bert-2f4f16eff5ad\n",
        "\n",
        "\n",
        "5. This project uses the IMDB dataset compiled by Andrew Maas \n",
        "(see http://ai.stanford.edu/~amaas/data/sentiment/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUzR97rjgW3P"
      },
      "source": [
        "Install Tranformers library from huggingface:\n",
        "https://huggingface.co/transformers/examples.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fl8o42QgUVe",
        "outputId": "30e5216e-3a55-4bd4-bf63-ecc9dda44e18"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7LpeS9whj_9"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkVPyAfrzMVw"
      },
      "source": [
        "## Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional, Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVz7dEace2jI"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrMMFVoGkWlM"
      },
      "source": [
        "!pip install -q tensorflow-datasets"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPfmzQL3fXl_",
        "outputId": "f4c880b9-2298-4f6c-92ef-6a6741e850d9"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews', \n",
        "          split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "          as_supervised=True,\n",
        "          with_info=True)\n",
        "print('info', ds_info)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split (Split('train'), Split('test')), from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "info tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    version=1.0.0,\n",
            "    description='Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=100000,\n",
            "    splits={\n",
            "        'test': 25000,\n",
            "        'train': 25000,\n",
            "        'unsupervised': 50000,\n",
            "    },\n",
            "    supervised_keys=('text', 'label'),\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7Qd5x4-k7oR",
        "outputId": "f7c88421-e7b3-41db-985b-655e1723ed12"
      },
      "source": [
        "for review, label in tfds.as_numpy(ds_train.take(5)):\n",
        "    print('review', review.decode()[0:50], label)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review This was an absolutely terrible movie. Don't be lu 0\n",
            "review I have been known to fall asleep during films, but 0\n",
            "review Mann photographs the Alberta Rocky Mountains in a  0\n",
            "review This is the kind of film for a snowy Sunday aftern 1\n",
            "review As others have mentioned, all the women that go nu 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVIi5MyEin0E"
      },
      "source": [
        "Map the words and labels to the format needed by BERT. This can be done using the functions below or the encode_plus function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qqBVS1k97Zw"
      },
      "source": [
        "# can be up to 512 for BERT\n",
        "max_length = 512\n",
        "batch_size = 6\n",
        "\n",
        "def convert_example_to_feature(review):\n",
        "  # combine step for tokenization, WordPiece vector mapping, adding special tokens as well as truncating reviews longer than the max length\n",
        "  return tokenizer.encode_plus(review, \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = max_length, # max length of the text that can go to BERT\n",
        "                padding='max_length', # add [PAD] tokens\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )\n",
        "\n",
        "# map to the expected input to TFBertForSequenceClassification, see here \n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, label\n",
        "\n",
        "def encode_examples(ds, limit=-1):\n",
        "\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []\n",
        "\n",
        "  if (limit > 0):\n",
        "      ds = ds.take(limit)\n",
        "    \n",
        "  for review, label in tfds.as_numpy(ds):\n",
        "\n",
        "    bert_input = convert_example_to_feature(review.decode())\n",
        "  \n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append([label])\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJx2nT_ri0ve"
      },
      "source": [
        "# train dataset\n",
        "ds_train_encoded = encode_examples(ds_train).shuffle(10000).batch(batch_size)\n",
        "# test dataset\n",
        "ds_test_encoded = encode_examples(ds_test).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJqKw6-lUPG"
      },
      "source": [
        "###Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW6Aim6KkHy8",
        "outputId": "392389ae-b20d-402e-b7bb-77ee2f73dfa3"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\n",
        "number_of_epochs = 1\n",
        "\n",
        "\n",
        "# model initialization\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# choosing Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGS-RDqPm8NP",
        "outputId": "cb27f9f5-1b68-4a3a-9580-e19fb6eb37d0"
      },
      "source": [
        "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4167/4167 [==============================] - 3194s 763ms/step - loss: 0.3058 - accuracy: 0.8664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTrwHMNin6pe"
      },
      "source": [
        "Evaluation on test set. \n",
        "\n",
        "In this notebook we did not use a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4OgtruF7sft",
        "outputId": "cd3b9506-6269-496e-f5d9-c8abee9a1b78"
      },
      "source": [
        "results = model.evaluate(ds_test_encoded)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4167/4167 [==============================] - 1089s 261ms/step - loss: 0.1792 - accuracy: 0.9316\n",
            "loss: 0.179\n",
            "accuracy: 0.932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPjq7Y2qzWkZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}